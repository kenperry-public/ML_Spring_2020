{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "outputs": [
    {
     "data": {
      "text/latex": [
       "$$\n",
       "\\newcommand{\\x}{\\mathbf{x}}\n",
       "\\newcommand{\\tx}{\\tilde{\\x}}\n",
       "\\newcommand{\\y}{\\mathbf{y}}\n",
       "\\newcommand{\\b}{\\mathbf{b}}\n",
       "\\newcommand{\\c}{\\mathbf{c}}\n",
       "\\newcommand{\\e}{\\mathbf{e}}\n",
       "\\newcommand{\\z}{\\mathbf{z}}\n",
       "\\newcommand{\\h}{\\mathbf{h}}\n",
       "\\newcommand{\\v}{\\mathbf{v}}\n",
       "\\newcommand{\\w}{\\mathbf{w}}\n",
       "\\newcommand{\\W}{\\mathbf{W}}\n",
       "\\newcommand{\\X}{\\mathbf{X}}\n",
       "\\newcommand{\\KL}{\\mathbf{KL}}\n",
       "\\newcommand{\\E}{{\\mathbb{E}}}\n",
       "\\newcommand{\\ip}{\\mathbf{{(i)}}}\n",
       "%\n",
       "% Test set\n",
       "\\newcommand{\\xt}{\\underline{\\x}}\n",
       "\\newcommand{\\yt}{\\underline{\\y}}\n",
       "\\newcommand{\\Xt}{\\underline{\\X}}\n",
       "\\newcommand{\\perfm}{\\mathcal{P}}\n",
       "%\n",
       "% \\ll indexes a layer; we can change the actual letter\n",
       "\\newcommand{\\ll}{l}\n",
       "\\newcommand{\\llp}{{(\\ll)}}\n",
       "%\n",
       "\\newcommand{Thetam}{\\Theta_{-0}}\n",
       "\n",
       "%\n",
       "% \\tt indexes a time step\n",
       "\\newcommand{\\tt}{t}\n",
       "\\newcommand{\\tp}{{(\\tt)}}\n",
       "%\n",
       "\\newcommand{\\loss}{\\mathcal{L}}\n",
       "\\newcommand{\\cost}{\\mathcal{L}}\n",
       "%\n",
       "%                     \n",
       "\\newcommand{\\pdata}{p_\\text{data}}\n",
       "\\newcommand{\\pmodel}{p_\\text{model}}\n",
       "%\n",
       "% SVM\n",
       "\\newcommand{\\margin}{{\\mathbb{m}}}\n",
       "\\newcommand{\\lmk}{\\boldsymbol{\\ell}}\n",
       "%\n",
       "% Functions with arguments\n",
       "\\def\\xsy#1#2{#1^#2}\n",
       "\\def\\rand#1{\\tilde{#1}}\n",
       "\\def\\randx{\\rand{\\x}}\n",
       "\\def\\randy{\\rand{\\y}}\n",
       "\\def\\trans#1{\\dot{#1}}\n",
       "\\def\\transx{\\trans{\\x}}\n",
       "\\def\\transy{\\trans{\\y}}\n",
       "%\n",
       "\\def\\argmax#1{\\underset{#1} {\\operatorname{argmax}} }\n",
       "\\def\\argmin#1{\\underset{#1} {\\operatorname{argmin}} }\n",
       "\\def\\max#1{\\underset{#1} {\\operatorname{max}} }\n",
       "\\def\\min#1{\\underset{#1} {\\operatorname{min}} }\n",
       "%\n",
       "\\def\\pr#1{\\mathcal{p}(#1)}\n",
       "\\def\\cnt#1{\\mathcal{count}_{#1}}\n",
       "\\def\\node#1{\\mathbb{#1}}\n",
       "%\n",
       "\\newcommand{\\floor}[1]{\\left\\lfloor #1 \\right\\rfloor}\n",
       "\\newcommand{\\ceil}[1]{\\left\\lceil #1 \\right\\rceil}\n",
       "%\n",
       "\n",
       "$$\n"
      ],
      "text/plain": [
       "<IPython.core.display.Latex object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%run Latex_macros.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# What is the \"Recipe\" for Machine Learning\n",
    "\n",
    "We will define a methodical approach to solve problems using Machine Learning.\n",
    "\n",
    "This is the *Recipe for Machine Learning*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<table>\n",
    "    <tr>\n",
    "        <th><center>Recipe for Machine Learning</center></th>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td><img src=\"images/ML_process.jpg\" width=800></td>\n",
    "    </tr>\n",
    "</table>\n",
    "​"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "There are no short-cuts !\n",
    "\n",
    "Each step in the Recipe  both prepares you for the next and, crucially, gives you *deeper insight*\n",
    "which improves the result."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Get the data\n",
    "\n",
    "The first step is obtaining data for training and evaluation.\n",
    "\n",
    "This is often the most challenging part !\n",
    "- Interesting data is scattered: requires collection\n",
    "- Supervised Learning requires labelled data; where do the labels come from ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "In this course, we will usually provide you with data so you will be mostly insulated from this challenge.\n",
    "- Learning how to obtain data is a good skill to learn\n",
    "    - Web scraping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Let's visit the notebook section [Get the Data](Recipe_for_ML.ipynb#Recipe-step-A:-Get-the-data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Look at the data\n",
    "\n",
    "Always put your eyes on the data !\n",
    "- You will learn about its \"shape\":\n",
    "    - tabular ?  \n",
    "    - What are the attribute names ?\n",
    "    - What are the types of the attributes ? Numeric ? Text ?\n",
    "- You will learn about potential data problems\n",
    "    - missing data\n",
    "    - strange values\n",
    "    \n",
    "Don't even try to do anything with your data until you have at least the most basic understanding by\n",
    "performing an inspection."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Let's visit the notebook and [Look at the data](Recipe_for_ML.ipynb#Recipe-A.2:-Have-a-look-at-the-data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Define a Performance Measure\n",
    "\n",
    "Our model \"learns\" from training data, so we might expect it to predict well on training examples\n",
    "- the training examples are *in sample*: used by the model to learn $\\Theta$\n",
    "\n",
    "How well should I expect the model to predict on  examples not encountered during training ?\n",
    "- \"test\" examples never seen during training, called *out of sample* examples\n",
    "\n",
    "We define a *Performance Measure* to measure how well the model performs out of sample."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Let's visit the notebook and [Define a Performance Measure](Recipe_for_ML.ipynb#select_performance_measure)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Performance Measure versus Loss Function\n",
    "\n",
    "There may some confusion between the Performance Measure and Loss functions\n",
    "- they are both evaluated over a set of examples\n",
    "- they both measure performance of some sort\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "A Performance Measure can be thought of as the promise you make\n",
    "- to a client/customer/boss\n",
    "- on how well your model will perform on arbitrary, yet to be seen examples (non-training, out-of-sample)\n",
    "\n",
    "In order for you to have confidence in your promise\n",
    "- you evalute the Performance Measure on *out of sample* examples\n",
    "- using the out of sample examples *once* so that your model doesn't learn from them (i.e., become in-sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "To illustrate, let\n",
    "- $\\X$ denote our set of training examples, $\\x^\\ip \\in \\X$\n",
    "- $\\Xt$ denote a set of test examples (out of sample: not used in training), $\\xt^\\ip \\in \\Xt$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<table>\n",
    "    <tr>\n",
    "        <th><center>Loss on  <i>Training example</i></center></th>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td><img src=\"images/Intro_training.jpg\"</td>\n",
    "    </tr>\n",
    "</table>\n",
    "​"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<table>\n",
    "    <tr>\n",
    "        <th><center>Performance on  <i>Test example</i></center></th>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td><img src=\"images/Performance_measure.jpg\"</td>\n",
    "    </tr>\n",
    "</table>\n",
    "​"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "- A Performance Measure\n",
    "    - is a property of the *problem* (not the model used to solve the problem)\n",
    "    - you may have more than one Performance Measure\n",
    "        - each expressing some desired quality of the prediction\n",
    "    - is evaluated *out of sample*, that is, on non-training examples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "- The Loss Function\n",
    "    - is a property of a *model*: it guides a particular model's search for the best $\\Theta$\n",
    "        - different models may have different Loss Functions\n",
    "            - but the *problem's* Performance Metric is the same\n",
    "    - is evaluated *in sample*, that is, on training data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Create a test set\n",
    "\n",
    "Let's visit the notebook and [Create a test set](Recipe_for_ML.ipynb#Recipe-A.4:-Create-a-test-set-and-put-it-aside-!)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Exploratory Data Analysis\n",
    "\n",
    "This is one of the key steps of a good Data Scientist.\n",
    "\n",
    "Besides \"seeing\" the data, we need to hear it: what is it telling us that may aid prediction\n",
    "\n",
    "- any problems with the data that would inhibit learning ?\n",
    "- any apparant relationship between target and a single feature ?\n",
    "- any apparant relationship between target and combinations of features ?\n",
    "- any apparant relationship between features ?\n",
    "- what are the relative magnitudes of features ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Often,  understanding the data intimately can lead to\n",
    "- transformations of the features that will aid prediction\n",
    "- improved models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Let's visit the notebook and perform [Exploratory Data Analysis](Recipe_for_ML.ipynb#Recipe-Step-B:-Exploratory-Data-Analysis-(EDA))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Prepare the data\n",
    "\n",
    "It is not always the case that the data in \"raw\" form is adequate for modelling\n",
    "- Cleanliness\n",
    "    - dealing with missing data or anamolous values\n",
    "- Numericalization\n",
    "    - Converting non-numeric/categorical data into appropriate numbers\n",
    "- Scaling, normalization\n",
    "    - putting features on compatible scales\n",
    "- Creating new \"synthetic\" features from original features\n",
    "    - Knowing when/how to do this is what separates a good Data Scientist from an average one\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "We will call the process of preparing the data *Transformations* or *Feature Engineering*.\n",
    "\n",
    "Transformation takes an example in raw form and creates a \"processed\" example suitable for modelling.\n",
    "\n",
    "It is important to emphasize that \"example\" means either training, validation, or test.\n",
    "\n",
    "Always apply transformations consistently to all example\n",
    "- In particular: transformations applied to a training example should be applied to test examples at inference time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Let's visit the notebook [Prepare the data](Recipe_for_ML.ipynb#Recipe-Step-C:-Prepare-the-data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Train a model\n",
    "\n",
    "The model is our \"predictor\": the machine that takes features and produces predictions.\n",
    "\n",
    "All the prior steps of the recipe were \"prep-work\": preparing the ingredients (data) for cooking (modelling)\n",
    "\n",
    "Unlike actual cooking, this step is *iterative*\n",
    "- we try one model\n",
    "- fit the model to the data\n",
    "- examine the results critically\n",
    "    - has the Loss improved ? Is it good enough ?\n",
    "    - learn lessons from errors\n",
    "- improve the model and repeat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "The iterative nature is often overlooked in the rush to learn models.\n",
    "\n",
    "But Error Analysis is key to guiding us on the weaknesses of the existing model, and to improving the model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<table>\n",
    "    <tr>\n",
    "        <th><center>Iterative training</center></th>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td><img src=\"images/ML_process_iterate.jpg\"></td>\n",
    "    </tr>\n",
    "</table>\n",
    "​"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Select a model and train it\n",
    "Let's move to the notebook and [Select and Train a model](Recipe_for_ML.ipynb#Recipe-Step-D:-Train-a-model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Validation and Cross Validation\n",
    "\n",
    "We have just fit our first model and evaluated the Performance Measure on the test examples.\n",
    "\n",
    "Can we continue trying to improve the model and re-evaluate the Performance metric on the same test examples ?\n",
    "\n",
    "No !  By seeing the \"out of sample\" examples, we have made them \"in-sample\"\n",
    "- We can improve our model by causing it to perform well on the test examples\n",
    "- Result won't be a realistic measure of performance on unseen examples\n",
    "    - Like seeing the questions before the exam !"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Fortunately, there is a way to both\n",
    "- save your test examples for single use\n",
    "- create pseudo-test examples that can be reused\n",
    "\n",
    "Let's return to the notebook and explore [Validation and Cross Validation](Recipe_for_ML.ipynb#Recipe-D.3:--Validation-and-Cross-Validation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Error analysis\n",
    "\n",
    "Now that we have fit a model, we have \n",
    "- an estimate of Performance Measure using Validation/Cross Validation\n",
    "\n",
    "If this measures is not \"good enough\", we will want to improve predictions\n",
    "- we might improve prediction by *changing* to a different model\n",
    "- we might improve prediction by *adding features*\n",
    "\n",
    "How do we know if the Performance Measure is \"good enough\" and how to improve our model ?\n",
    "\n",
    "Unfortunately, many people (and courses!) don't explore this enough.\n",
    "\n",
    "Let's move to the notebook to [Examine the errors](Recipe_for_ML.ipynb#Recipe-D.4:--Error-analysis)\n",
    "to see why a deeper analysis may be warranted.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Iterate: Linear Regression with higher order features\n",
    "\n",
    "The Error Analysis we performed on our first model (single non-constant feature) suggested a need for improvement.\n",
    "\n",
    "Two types of improvement come to mind\n",
    "- Hypothesis iteration: try  a different model\n",
    "    \n",
    "- Feature iteration: change/add to the features of the current model\n",
    "    - adding a previously discarded feature\n",
    "    - creating a synthetic feature\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "We will take the approach of adding a feature.\n",
    "\n",
    "Let's extend Linear Regression with [higher order features](Linear_Regression_HigherOrderFeatures.ipynb) (separate notebook)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## When to stop iterating\n",
    "\n",
    "Adding second order features resulted in a perfect in-sample fit, so there is no point iterating further.\n",
    "\n",
    "In general, this will not be the case.\n",
    "\n",
    "How do we know that our model is \"good enough\" ?\n",
    "\n",
    "We will postpone this question until we do a Deeper Dive in [Bias and Variance](Bias_and_Variance.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Fine tune\n",
    "\n",
    "There are often \"tweaks\" that can be applied to a near-final model in order to squeeze out increase\n",
    "performance.\n",
    "\n",
    "For example: many models have *hyper parameters*.\n",
    "\n",
    "These are values that are *chosen* at model construction, rather than *discovered* by fitting during training ($\\Theta$)\n",
    "\n",
    "- the degree $d$ of the polynomial when constructing higher order features $\\x^d$\n",
    "- whether to include/exclude the interecept $\\Theta_0$ in a Linear Regression\n",
    "- strength of the regularization penalty (coming attraction: to be discussed together with the Loss function)\n",
    "- the $k$ in K Nearest Neigbhors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Perhaps a different choice of a hyper-parameter would improve the model ?\n",
    "\n",
    "We can try many choices before settling on the one giving the best Performance Metric.\n",
    "\n",
    "Hyper parameters search is another reason for using Cross Validation\n",
    "- we can't use the Test set more than once\n",
    "- with a single Validation set: we might overfit to the validation set\n",
    "    - that is, choose a value for the hyper parameter that is best for this *single* validation set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "We will perform a Deeper Dive in Fine Tuning in a separate module."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Recap\n",
    "\n",
    "- We have briefly detailed the multi-step process for Machine Learning\n",
    "- This should be a model for you (and your assignments !)\n",
    "- We will perform Deeper Dives on some of the steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done !\n"
     ]
    }
   ],
   "source": [
    "print(\"Done !\")"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "370.594px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
